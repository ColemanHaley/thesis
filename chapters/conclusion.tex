\chapter{Conclusion}\label{ch:conclusion}
In this thesis, I have argued for an empirical, quantitative, and computational approach to defining and studying comparative concepts in linguistic typology. Drawing on the history of empirical and computational approaches in phonological and semantic category typology, I have proposed that developments from deep learning can take on an analogous role for other functional comparative concepts to the empirical measures that allowed these problems to be computationally modelled, defining an empirical conceptual space over which we can form generalizations.

I apply this idea to the notion of a spectrum of {\em lexicality}--a correlation between the formal size and independence of linguistic signs, and their semantic contentfulness and relationality. The notion of semantic contentfulness, while often appealed to in intuitions about putative binaries like the lexical--functional distinction or the inflection--derivation distinction, has been difficult to formalize, with traditional linguistic approaches not offering a principled basis for measuring it, and conventional computational approaches reducing to frequency. Partly as a result, these binaries have been argued by some to hold no theoretical or empirical weight \citep{haspelmath-2024-inflection,bruening-2018-lexicalist}. Deep learning offers a new way forward, by providing high-dimensional semantic representations that can be used to operationalize semantic contentfulness in new ways.

I have provided computational studies at three different ``levels'' of lexicality. Part I provides a detailed study of the inflection--derivation distinction, \cref{ch:grounded} studies the lexical--functional distinction, and \cref{ch:splitlump} studies distinctions between the major lexical classes of nouns, verbs, and adjectives. In each case, I have shown that deep learning-based measures reveal consistent cross-linguistic patterns across these problematic distinctions. This suggests that these distinctions have been relatively consistently applied cross-linguistically, even if they are gradient and fuzzy.

\section{Contributions}
To summarize, the main contributions of this thesis are:
\begin{enumerate}
  \item Argument comparative concepts
  \item A review of comparative concepts in computational typology
  \item Argument lexicality
  \item A four measure framework for
  \item Classification experiments demonstrating
  \item Groundedness
  \item Evaluation of relationship between groundedness and lexical--functional
  \item A theoretical argument relating the groundedness findings to lexical
  \item An empirical study of a language that splits a major lexical class
  \item Tensedness Correlation
\end{enumerate}

\section{Limitations and future directions}

\subsection*{Language coverage}
From a typological perspective, probably the most important limitation of the work here, and to a certain extent the methods proposed, is the language coverage and selection. In this thesis, we have used convenience samples which are biased to (Indo-)European, western, wealthy, highly-resourced languages. Gold-standard typological studies ideally use a wide range of languages, taking into account cultural, areal, linguistic, and phylogenetic diversity. Typological is a challenging problem, receiving substantial attention in traditional typology \citep[pp. 19--30]{dryer-1989-large,miestamo-et-al-2016-sampling, croft-2002-typology}, and recently, in computational linguistics and natural language processing \citep{ploeger-et-al-2024-what,ploeger-et-al-2025-principled}. The methods used in this thesis are data-hungry, requiring both substantial data in individual languages, and (for the statistical and classification experiments) a reasonable number of languages. This fact motivates the choice of languages in this thesis, but also limits confidence in the cross-linguistic generality of the findings. Still, the phenomena studied here have sometimes been studied computationally in individual languages (e.g. \citealp{bonami-et-al-2018-inflection,rosa-et-al-2019-unsupervised}), but have not been studied across as diverse a set of languages as here. I thus see this work as a first step towards more comprehensive cross-linguistic computational studies of these distinctions.

One limiting factor is the coverage of the datasets used. For example, the UniMorph dataset used in Part I has broad language coverage for inflection, but derivational paradigms are available for a smaller and much more Indo-European biased set of languages. Large-scale derivational resources are not widely available, and do not include many languages with the richest and most typologically interesting derivational systems (e.g. many languages of the Americas). Computational approaches could help to alleviate this problem. For example, some low-resource languages have finite-state morphological analysers and generators available, which could be used to generate derivational paradigms, either as silver-standard datasets, or as a starting point for manual annotation. I have explored this approach in preliminary work \citep{haley-2025-unlocking}, producing silver-standard derivational networks for Saint Lawrence Island Yupik and West Greenlandic. The collection of more comprehensive derivational datasets cross-linguistically has the potential to substantially advance understanding in morphological typology.

Similarly, the coverage of both image captioning datasets and Stanza part-of-speech taggers limits the languages studied in Part II. While alternative POS taggers could be used to add the missing languages from the Crossmodal-3600 dataset (Thai, Tagalog, Bengali, Swahili, and Maori), the point remains that the languages are still limited to those with large captioning datasets, corpora, and POS taggers.

It is unclear how many more of the world's languages could be studied with the methods in this thesis. There is increasing interest in data-efficient modelling of language, such as in the BabyLM challenge \citep{warstadt-et-al-2023-findings, hu-et-al-2024-findings,charpentier-et-al-2025-findings}, which focuses on training language models with ``cognitively plausible'' amounts of data (10-100M words). This scale of model does demonstrate sensitivity to fairly fine-grained linguistic phenomena \citep{misra-et-al-2024-language}, but this quantity of data is still out of reach for most of the world's languages. While transfer learning techniques like fine-tuning and adapters \citep{ansell-et-al-2022-composable} can help to adapt models to lower-resource languages, and multilingual modelling can help share information across languages \citep{brinkmann-et-al-2025-large}, these techniques may bias the models toward the properties of higher-resource languages, creating problems for typological study \citep{papadimitriou-et-al-2023-multilingual}. Lastly, today's large language models introduce both prospects and challenges for typological research. On the one hand, there is some evidence that such models can learn phenomena in very low-resource languages from grammatical descriptions alone \citep{tanzer-et-al-2024-benchmark,vasselli-et-al-2024-applying}, suggesting a path toward increasing the resource status of languages with as little as a grammar or a few hundred sentences of data. On the other hand, such models also readily produce outputs in low-resource languages which matches superficial characteristics such as orthography and common words, but are otherwise nonsensical \citep{palmer-2025-keynote}, representing an additional challenge just not for typological research, but for the vitality of the speech communities of endangered languages.

Ensuring that these technologies are developed and deployed in a way that benefits all the world's languages is a critical challenge for the field going forward. This involves not only technical challenges, but careful engagement with the language communities with which we work \citep{bird-2020-decolonising, schwartz-2022-primum}, the colonial legacies in natural language processing and typology, and the environmental impact of the methods we use \citep{strubell-etal-2019-energy}.

\subsection*{Operationalizations of distinctions} Throughout this thesis, I have related my empirical measures to distinctions as they have been used in existing tools and datasets. For example, in Part I, I study the relationship between my four measures and the inflection--derivation distinction {\em as reflected in the UniMorph 4.0 dataset} \citep{batsuren-et-al-2022-unimorph}, and in \cref{ch:grounded}, I study word classes {\em as operationalized in Universal Dependencies} \citep{demarneffe-et-al-2021-universal}. A natural objection to certain findings here, then, is that I have selected the {\em wrong} operationalization of a particular distinction, and that if I had grouped constructions differently I would have seen different results (e.g. a more clear-cut distinction between inflection and derivation). This is certainly a limitation of the present work, but it is not necessarily a weakness.
\
For example, the inflectional vs. derivational status of a construction in UniMorph is based on how Wiktionary editors for a language choose to organize morphological information. In this way, it directly reflects the most cynical interpretation of \citet{haspelmath-2024-inflection} in describing inflection and derivation as {\em traditional comparative concepts}---that it is, effectively, a convention of dictionary organization. That we find a high degree of cross-linguistic consistency in terms of our measures is thus all the more surprising given the lack of linguistic attention paid to the classification of constructions. Further, the choice of using the categories unmodified from UniMorph or Universal Dependencies is motivated by the high likelihood that these operationalizations will be {\em used} as the comparative concepts in future computational studies---this thesis thus serves as a form of external empirical {\em validation}. All this being said, an interesting direction for future work would certainly be to try different operationalizations of the distinctions with the approaches in this thesis, contrasting them with the findings here. Indeed, this direction is actively being pursued by researchers investigating how different ways of grouping derivational constructions influence the empirical differences between inflection and derivation in our framework \citep{kyjanek-et-al-2025-theoretical}.

Additionally, in \cref{ch:grounded} and \cref{ch:splitlump}, we rely on {\em automatic classifiers} to obtain part-of-speech tags and identify {\em na-} and {\em i-}adjectives. These classifiers are not perfect, and thus introduce noise into our analyses. Thus, improvements in such classifiers would improve the reliability and validity of the findings here, though I believe they are unlikely to fundamentally alter the pattern of results.

% \subsection*{Data comparability}

% \subsection*{The classification approach}

\subsection*{Questions of groundedness}
While in this thesis I have focused on groundedness as it relates to lexicality distinctions, and specifically among word classes, there are many other interesting linguistic phenomena to which the method could be applied. I will sketch how groundedness and grounded approaches could be applied to some other phenomena here. These phenomena are united by their relationship to information structure and/or spatial structure, motivating the use of images and visual groundedness as tools.

\paragraph*{Inflection, derivation, and construal} Naturally, given the difference in methodology between Part I and Part II of the thesis, there arises a natural question of how the groundedness measure would relate to inflection and derivation. This analysis involves overcoming a few technical challenges. First, I would need to identify derivational and inflectional constructions in image captioning datasets. This is not straightforward, especially in the cross-linguistic setting. First, I would need some kind of classifier to annotate relations at scale, and computational tools tend to focus on inflectional morphology, leading to a lack of tools for automatically identifying derivational relations. Second, derivational relations may be less abundant in image captioning datasets, due to their concrete nature.

Lastly, language models produce probability estimate at the subword token level, which may not align cleanly with morphological boundaries.\footnote{Indeed, in some languages, identifying certain bound morphemes with any orthographic substring may not be possible at all.} While one can {\em aggregate} subword probabilities to measure the probability of longer sequences, one cannot straightforwardly measure the probability of a {\em portion} of one or more subword tokens (e.g. if we wanted to score the groundedness of {\em -ed} in {\em walked}, and it was tokenized as \texttt{\_wal ked}). It has recently been shown that one can in principle refactorize a model to compute probabilities at arbitrary substring boundaries \citep{vieira-et-al-2025-language}, but whether such probabilities are of the same quality as the original model's probabilities remains unclear. Alternatively, \citep{minixhofer-et-al-2024-zeroshot} propose a method for changing the tokenization of a model with a hypernetwork rather than retraining the whole model---such a model could be trained to adapt PaliGemma to morpheme-aligned tokenization.

Despite these challenges, I believe that applying the groundedness measure to inflection and derivation would be a fruitful direction for future work. Another interesting question exists among derivations. Derivational {\em transpositions}---derivations which change the lexical class of a word---have been described in cognitive linguistics as a form of \textsc{construal} \citep{croft-2001-radical}. That is, they represent a repackaging of a concept to ``play the role of'' a different type of concept. For example, the noun {\em running} construes the event of running as an entity rather than an event or action. Given that we see differences in groundedness among nouns, verbs, and adjectives, it would be interesting to see how properties of images and groundedness affect the use of derivational construals. Are noun construals of events more highly grounded? Are visually salient events or properties more likely to be construed as nouns? This would still require some technical apparatus to identify derivational relations, but would side-step the problem of tokenization.

\paragraph*{Adpositions} In \cref{ch:grounded}, we found adpositions did {\em not} exhibit intermediate groundedness values, but rather patterned clearly with function words. In future work, I hope to explore this finding in more detail. One explanation could be that most adposition tokens do not exhibit the properties that have led some to describe them as an intermediate class between content and function words--that is, that the adpositions in our datasets are dominated by high-frequency, grammaticalized uses, rather than more contentful uses like locative meanings, and those tokens which {\em do} behave in a more contentful way do exhibit higher groundedness values. Some exploratory analyses I have carried out in English suggest this may be the case (e.g. we found that {\em by} is much less grounded in passive constructions than when describing relationships between objects), but more work is needed to confirm this. Other interesting questions involve cross-linguistic exploration of force--dynamic adposition pairs like {\em in} vs. {\em on}, which have been difficult to characterize precisely and vary substantially cross-linguistically \citep{levinson-2003-space}. Are these construals relatively arbitrary, or do they relate to groundedness or other visual properties of the scenes they describe?

\paragraph*{Figure, ground, and the coordination--subordination distinction}

The distinction between \textsc{figure} and \textsc{ground} elements is fundamental to visual perception, as shown through the extensive literature on Gestalt psychology \citep{wagemans-et-al-2012-century}. In this framework, the figure refers to the element of a visual scene that stands out as the focus of attention, while the ground constitutes the background against which the figure is perceived. \citet{talmy-1972-semantic} introduced this distinction to cognitive linguistics, where it has been influential in describing a wide range of phenomena. For example, when we describe something with spatial relationships, we necessarily set up a figure--ground relationship, where the figure is the object being located, and the ground is the reference object (example due to \citealp[p. 314]{talmy-2000-cognitive}):
\begin{covexamples}[judgewidth={??}]
\item The bike [\textsc{figure}] is near the house [\textsc{ground}].
\item<*> The house [\textsc{figure}] is near the bike [\textsc{ground}].
\end{covexamples}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/figure-ground.pdf}
  \caption{Conceptual space of complex sentence types as per \citet{croft-2001-radical}. }
  \label{fig:figure-ground}
\end{figure}

As this example shows, the figure--ground relationship is asymmetric, and is constrained by objective properties of the scene. The bike can be located with respect to the house, but not vice versa, because the house is larger and more stable in the scene. That being said, there are also many cases where multiple construals of a scene are possible (swapping the figure and ground), depending on attention and salience. Further, figure--ground relationships have a tight relationship to \textsc{coordination}, because conjunctive coordination construes multiple entities as a \textsc{complex figure}:
\begin{covexamples}
\item A cat and a dog [\textsc{complex figure}].
\item A cat [\textsc{figure}] is next to a dog [\textsc{ground}].
\end{covexamples}
Visual groundedness could be used to study how different entity combinations and visual scenes influence figure--ground relationships. I expect that entities that are similarly grounded are more able to alternate in figure--ground construals, and more able to be coordinated, while entities with very different groundedness values would be less able to do so. This also raises interesting questions cross-linguistically---do languages differ in when they allow figure--ground alternations? This could be a matter of degree (having more or less flexible figure--ground construals), or of kind (having different figure--ground construals depending on semantic properties).

This kind of figure--ground relationship is not limited to spatial descriptions of objects, but extends to events and actions as well \citep[pp. 320--361]{croft-2001-radical}. That is, clauses can be coordinated, or construed in figure--ground relationships, to express temporal relationships or salience. This interacts structurally with how dependent the clauses are on one another--for example, \textsc{complement} clauses (e.g. {\em She told him [that she found a job]}) form a complex ground like simple coordinated clauses. \cref{fig:figure-ground} shows a conceptual space of complex sentence types as they relate to figure--ground properties. As shown in the figure, cross-linguistically, there are a number of construction types expressing intermediate amounts of integration between the clauses and intermediate figure--ground relationships. Visual groundedness could be used to study how these different construction types relate to the figure--ground properties of the events and participants they describe. Do intermediate construction types involve events with more intermediate groundedness relationships? Do people or models prefer certain construals for certain visual scenes?

% \paragraph*{The argument--adjunct distinction}

% \paragraph*{The modification--reference continuum}

\paragraph*{Beyond groundedness scores} For any of these phenomena, it may be fruitful to go beyond the groundedness score I proposed in Part II, to explore more complex functions of the image and language model probabilities, or to use properties of the representations themselves. For example, in \cref{ch:grounded}, I conducted a preliminary exploration of the uncertainty coefficient as an alternate measure of groundedness which is not sensitive to overall informativity, which may be useful for certain phenomena. In some cases, it may be useful to explore the full map of image and language model probabilities, rather than collapsing them to a single score (for example, to explore whether certain phenomena cluster in a particular region of the space). Additionally, it may be useful to explore attribution metrics for vision-language models \citep{jiang-et-al-2025-vision}, to see what regions of the image are most responsible for the model's predictions. It may be possible to learn functions over these attribution maps to provide more abstract image-based descriptions of the functions that characterize different linguistic items. Such methods are still in their infancy, suggesting that there is much room for future work in this direction.

\subsection*{Images as meaning?}
Our operationalization of meaning as an image in Part II is necessarily a simplification. Notably, the choice of images over videos (motivated by model quality and availability) as the representation of meaning has major implications for verbs, which tend to have meanings which are more temporally extended. This choice also has substantial implications about the variety of language which can be analysed--many types of language use, such as metaphoric extension, are likely to be much less frequent in image captions than in other domains of language use: such phenomena are perhaps best studied using a different technique. Similarly, This problem is compounded by the fact that existing multilingual corpora for these datasets remain fairly small--thus the analysis of long-tail phenomena in language using these methods is likely not yet possible. Our mathematical approach, however, is not limited to images---any type of representation which we could condition a language model on could be used. Below, I sketch some options, their challenges, and their potential.

\paragraph*{Beyond single images} One possibility is to condition on a sequence of images rather than a single image, as in visual storytelling paradigms like the Frog Story \citep{berman-et-al-1994-relating}. This paradigm has already proved useful in typology, and could be enhanced by the fine-grained quantitative measures proposed here. This approach is on the edge of what is possible with current multilingual VLMs---some colleagues and I have recently explored this direction in a submission currently under review exploring the hypothesis that language tries to spread information uniformly within utterances (the \textsc{Uniform Information Density Hypothesis}; \citealp{levy-et-al-2006-speakers}). While video captioning models face substantial challenges due to the extreme amounts of data in videos, techniques are likely to improve in the near feature, allowing for better study of temporally extended and dynamic phenomena. Narratively-oriented models and tasks may also contain more linguistic variety, as captions tend to be restricted in terms of verb use, tense, and lexical aspect, while visual storytelling datasets are more varied \citep{alikhani-et-al-2019-caption}. This could be particularly useful for the coordination--subordination phenomena discussed above.

\paragraph*{Text-derived meaning representations} To overcome the limitations on language use and lack of multimodal multilingual data, another possibility is to use meaning representations derived from text. While at first glance this may seem circular, since we would be conditioning on a text to generate that text, there are some modelling approaches which could make this sensible. First, some vision encoders like CLIP \citep{radford-et-al-2021-learning} are trained to encode images and captions into a shared space; as such, they produce text encodings which should maximize similarity for captions of similar images---thereby producing a representation more abstract than the text itself. If we train a language model conditioned on these text encodings (similarly to the structure of VLMs discussed in \cref{sec:vlm}), it should be possible to measure groundedness with respect to these text-derived representations. Alternatively, there are a number of sentence embedding models which use paraphrases and parallel data to produce meaning representations, such as Language-agnostic BERT Sentence Embedding (LaBSE; \citealp{feng-etal-2022-languageagnostic}). These models aim to produce representations which capture a representation of meaning which is invariant to the language of expression, and have been widely used in machine translation for forming parallel corpora \citep{haddow-etal-2022-survey}. However, these models have not been studied from the typological context directly, and it is unclear how invariant they are to formal similarities (e.g. shared vs. different strategies). However, if these models do capture meaning in a way that is invariant to form, they could be used to study groundedness in a text-only setting, allowing for the study of a much wider variety of languages and linguistic phenomena.

\subsection*{Lexicality beyond contentfulness}
While in this thesis I have primarily focused on the way semantic contentfulness relates to linguistic organization, this may only be a small part of the story. In \cref{ch:predicting}, I explore an interaction of formal properties and semantic contentfulness, which may be useful at the word/root level as well. Similarly, engagement with the literature on the inflection--derivation distinction suggests idiosyncrasy of composition as a criterion for derivation, which would be interesting to study with lexical roots and free functional elements--are more idiosyncratic roots more contentful or more lexical in some other respect? Computational approaches for measuring idiomaticity \citep{klubicka-et-al-2023-idioms} could be adapted to study this question.

Other properties have also been proposed to relate to lexicality distinctions.  For example, \citet{talmy-2000-cognitive} points to the topological nature of grammatical meanings---grammatical meanings always encode {\em relative} distinctions, never {\em absolute} ones. Functional elements have also been argued to help structure or conceptualize information for communication \citep[pp. 225--226]{croft-2002-typology}. While I'm not sure how these properties could be operationalized in the framework of approaches in this thesis, I do believe there are a few promising directions for computational approaches to shed light on these questions. Recently, language universals have been studied through the lens of training language models on perturbed ``impossible'' or ``improbable'' versions of English and other real languages \citep{kallini-et-al-2024-mission,xu-et-al-2025-can}, with results suggesting that e.g. languages that violate Greenbergian word order correlations are harder for language models to learn, suggesting that these correlations reflect properties of language that facilitate statistical learning. This approach could be extended to study e.g. the learnability of systems with unattested obligatory marking, or with optional marking of certain obligatory categories. Perhaps such approaches could eventually provide new measures that facilitate the creation of a computational map that can be compared to data from human typological patterns.

% \section{Finis}