
\chapter{Predicting Inflection and Derivation Cross-linguistically}\label{ch:predicting}

\textcolor{red}{Despite the centrality of inflection and derivation to morphological description and many linguistic theories, there is substantial disagreement among linguists about the boundaries between these categories and what principles, if any, underlie the distinction. A common position is that the distinction is fundamentally \textsc{gradient} \citep{bybee-1985-morphology, spencer-2013-lexical, dressler-1989-prototypical, stekauer-2015-delimitation, bauer-2004-function}. This view has been supported by the existing literature which proposes computational measures of the properties of inflection and derivation \citep{bonami-et-al-2018-inflection, copot-et-al-2022-idiosyncratic, rosa-et-al-2019-attempting, bonami-et-al-2019-paradigm}, finding that while certain measures correlate the inflection--derivation distinction, there is substantial overlap between the categories. However, these studies have focused on one or two measures at a time, which is at odds with another common position in the linguistic literature: that inflection and derivation are \textsc{multidimensional} concepts \citep{spencer-2013-lexical, plank-1994-inflection, dressler-1989-prototypical, stekauer-2015-delimitation}, combining formal and functional aspects. Could inflection and derivation be better characterized by considering a more complete set of formal and distributional factors? In \cref{ch:corpus}, we proposed four measures, inspired by \citep{spencer-2013-lexical}, which align with many proposed properties of inflection and derivation, and found that these measures do indeed distinguish inflection and derivation to some extent, but with substantial overlap between the categories. In this chapter, we investigate whether, for a given construction, knowing just these measures is sufficient to predict its inflectional versus derivational status in UniMorph 4.0 \citep{batsuren-et-al-2022-unimorph}.}

To what extent can purely quantitative information about wordforms and corpus distribution recapitulate the linguistic intuitions, subjective tests, and comparative concepts encapsulated in the UniMorph annotations? If, across a variety of languages, belonging to different grammatical traditions, language families, and morphological typologies, the UniMorph annotations can be predicted with high accuracy based on our four measures, this would provide evidence that traditional concepts of inflection and derivation {\em do} closely correspond to intuitions about the different {\em types} of changes inflection and derivation induce, contra claims that the distinction carries no theoretical weight \citep{haspelmath-2024-inflection}.

To explore this question, we train two different types of machine learning models (a logistic regression classifier and a multilayer perceptron).
For each construction in our training set, the models are trained to predict whether the construction is inflectional or derivational, given just four input features: our measures of the magnitude and variability of the changes in wordform and distributional representations. Since we are interested in the cross-linguistic consistency of these predictors, the models are not given access to the input language or any of its typological features.
In experiments on 26 languages (including five from non-Indo-European families) and 2,772 constructions, we find that both models are able to predict with high accuracy whether a held-out construction is listed as inflection or derivation in UniMorph (83\% and 89\%, respectively, for the two models, compared to a majority-class baseline of 57\%).
We additionally find that our distributional measures alone are more predictive than our formal ones, and our variability measures alone are more predictive than our magnitude ones; nevertheless, combining all four features yields the best results.
Additionally, in Section~\ref{sec:canon}, we investigate which {\em inflectional categories} are particularly likely or unlikely to be classified as inflection by our model, notably finding that inherent inflection is particularly likely to be classified as derivation by our model, in line with \citeauthor{booij-1996-inherent}'s (\citeyear{booij-1996-inherent}) characterization of inherent inflection as non-canonical.

Together, these results provide large-scale cross-linguistic evidence that despite the apparent difficulty in designing subjective tests to definitively identify inflectional versus derivational relations, the comparative concepts of inflection and derivation are nevertheless associated with distinct and measurable formal and distributional signatures that behave relatively consistently across a variety of languages. Further analysis of our results does not, however, support the view of these concepts as clearly discrete categories. Although combining multiple measures reduces the amount of overlap in feature space between inflectional and derivational constructions, we still find a gradient pattern, with many constructions near the model's decision boundary between the two categories.
\section{Predicting inflection and derivation}\label{sec:classify}
In this section, we investigate how well the characterization of inflection and derivation given by the UniMorph dataset can be captured by our measures.
To do so, we use these measures as input features to simple classification models, which are trained to predict whether a given construction is listed as inflection or derivation in UniMorph, based only on those features. We created a train-validation-test split, randomly selecting 10\% of the constructions to reserve for validation and 20\% of the constructions for test. We used the validation set for model selection and hyperparameter tuning, and the test set was used exclusively for evaluation of the model accuracy. \added[id=r2]{We use the best model trained on this split for the analyses in Section~\ref{sec:canon} and Section~\ref{sec:langgen}. Within the current section, we evaluate our classification methods using stratified 5-fold cross-validation, to ensure the robustness of our findings to dataset splits.}

To understand the scenario in which these classifiers are operating, it is helpful to consider some simple baselines. First, we note that simply predicting the majority class across languages, inflection, achieves \added[id=r2]{a cross-validation accuracy of 57\%}, as there are simply more inflectional constructions than derivational ones in the UniMorph data. However, languages have a highly variable ratio of inflection to derivation constructions in UniMorph; classifying all the morphemes in a given {\em language} with the majority class for the language instead achieves an accuracy of $69 \pm 1\%$. In other words, a model could capture up to, but no more than, $\approx70\%$ of the variation in the UniMorph data purely by capturing which language a construction is in---without achieving any ability to distinguish between inflections and derivations within a language.
Note, however, that our models must predict whether a construction is inflectional or derivational without access to the language that construction comes from, so even reaching an accuracy of 70\% would indicate that the input features encode cross-linguistically informative distinctions.

We tested all possible combinations of features for each of our classification models, but we focus our discussion mainly on combinations corresponding to clear hypotheses about the factors that characterize inflection- and derivation-hood. First, we consider how much any \textbf{single} feature recovers the distinction from UniMorph. Secondly, we consider several combinations of two features:  \added[id=r2]{(A). \textbf{just variability $\big(\varform,\,\varemb\big)$}: Perhaps it is the case that only variability matters, as investigated in the embedding case by \citet{bonami-et-al-2018-inflection}. Or perhaps (B) \textbf{just magnitude} $\big(\chgform,\,\chgemb\big)$: only the magnitude of the changes in the components of the lexical entry matters, and variability is in practice a weak correlate or essentially redundant with magnitude. Further, it could be the case that the two measures of either (C) \textbf{form $\big(\chgform,\varform\big)$} or (D) \textbf{syntax/semantics $\big(\chgemb,\varemb\big)$} alone can recover as much information as all the metrics combined. Finally, of course, there is the hypothesis (E) that \textbf{all four features} are important---each contributing some amount of unique information for recovering the distinction from UniMorph. }

We explored these features with two types of models: a simple logistic regression classifier, which captures only linear relationships, and a multi-layer perceptron (MLP), which can capture non-linear relationships between features. The logistic regression classifier encodes the assumption that inflection and derivation can be separated by a hyperplane in feature space. If the feature values cluster, without intermediate regions, this corresponds to a categorical characterization of the distinction. If there are instead large regions with intermediate values, this corresponds to a gradient characterization of the distinction.\footnote{This issue of whether the distinction is gradient or categorical with respect to our measures is discussed further in Section~\ref{sec:grad}.} If the non-linear model is required to recover the distinction, then discontinuous areas in the feature space may fall in a certain category, which would not neatly correspond with linguistic intuitions.

First, we consider the logistic regression classifier. \replaced{As described in Section~\ref{sec:methodover}}{As shown in Table~1 and discussed in \citet{spencer-2013-lexical}}, the expectation from linguistic theory is that greater values of any measure should be associated with that construction being derivational. \deleted{While} Our analysis in Section~\ref{sec:individual} largely backs up this relation (with the relationship being inverted for form variability), \added{though} it is not clear to what degree this relationship is strictly linear.\deleted{; however, this type of linear modelling decreases the chance of our model picking up on statistical noise.}

Due to our highly-restricted selection of measures, we are able to create classifiers with all possible combinations of features. As shown in Figure~\ref{tab:featresults}, \replaced[id=r2]{the logistic classifier results best support the \textbf{just variability} hypothesis (A), with no notable performance gains achieved by adding other features in a linear-modelling setting.}{we find that the conjunction of all 4 features performs best, achieving a final test-set accuracy of 86\%; however, it is closely followed by the \textbf{just variability} hypothesis at 84\%. Similarly, the  best possible combination of the three features $\big(\chgemb, \varemb, \varform\big)$ achieves a test-set accuracy of 85\%, suggesting that \chgform provides little information which is not redundant with the other measures in a linear-modelling setting.}

\begin{figure}
  \small
  \centering
  % \renewcommand{\arraystretch}{0.75}
  \setlength{\tabcolsep}{2pt}
  \begin{tabularx}{\textwidth}{>{\centering}m{1cm}>{\centering}m{1.5cm}>{\centering}m{1.5cm}>{\centering}m{1.5cm}>{\centering}m{1.5cm}m{6.65cm}}
    \toprule
    &\multicolumn{4}{l}{Features}                    & Accuracy (
      \begin{tikzpicture}[x=1.2ex,y=1.2ex]
        \filldraw[pattern=north east lines](0,0)rectangle(1,1);
      \end{tikzpicture} = Logistic,
      \begin{tikzpicture}[x=1.2ex,y=1.2ex]
        \filldraw[pattern=dots](0,0)rectangle(1,1);
    \end{tikzpicture} = MLP) \\
    \midrule
    & \multicolumn{4}{l}{Majority class (Inflection)} & \otherchart{0.57}                  \\
    \hdashline
    & \chgform & –       & –        & –               & \chart{0.58}{0.01}{0.58}{0.01}     \\
    & –        & \chgemb & –        & –               & \chart{0.66}{0.01}{0.66}{0.01}     \\
    & –        & –       & \varform & –               & \chart{0.68}{0.01}{0.68}{0.02}     \\
    & –        & –       & –        & \varemb         & \chart{0.73}{0.01}{0.74}{0.01}     \\
    \rowcolor[gray]{0.9}[4pt]
    (A) & –        & –       & \varform & \varemb         & \chart{0.83}{0.01}{0.83}{0.01}     \\
    \arrayrulecolor{white}\hline\hline
    \rowcolor[gray]{0.9}[4pt]
    (B) & \chgform & \chgemb & –        & –               & \chart{0.67}{0.01}{0.67}{0.01}     \\
    \hline\hline
    \rowcolor[gray]{0.9}[4pt]
    (C) & \chgform & –       & \varform & –               & \chart{0.69}{0.01}{0.73}{0.01}     \\
    \hline\hline
    \rowcolor[gray]{0.9}[4pt]
    (D) & –        & \chgemb & –        & \varemb         & \chart{0.75}{0.01}{0.78}{0.01}     \\
    & \chgform & –       & –        & \varemb         & \chart{0.73}{0.01}{0.75}{0.01}     \\
    & –        & \chgemb & \varform & –               & \chart{0.73}{0.01}{0.73}{0.01}     \\
    & \chgform & \chgemb & \varform & –               & \chart{0.73}{0.01}{0.77}{0.01}     \\
    & \chgform & \chgemb & –        & \varemb         & \chart{0.76}{0.01}{0.81}{0.01}     \\
    & \chgform & –       & \varform & \varemb         & \chart{0.83}{0.01}{0.84}{0.01}     \\
    & –        & \chgemb & \varform & \varemb         & \chart{0.83}{0.01}{0.85}{0.01}     \\
    \rowcolor[gray]{0.9}[4pt]
    (E) & \chgform & \chgemb & \varform & \varemb         & \boldchart{0.83}{0.01}{0.89}{0.01} \\
    \arrayrulecolor{black}\bottomrule
  \end{tabularx}
  \caption{\added[id=r2]{Cross-validation accuracy and standard error} in reconstructing UniMorph's inflection–derivation distinction by various supervised classifiers. \added[id=r2]{Linguistically-motivated hypotheses referred to in the text are denoted with letters}}
  \label{tab:featresults}
\end{figure}

While our best logistic classification model can capture 26 points of variation more than predicting the majority class, it may be missing non-linear interactions between independent variables, or between an individual independent variable and the dependent variable.
To account for such non-linear relationships, we fit a multi-layer perceptron (MLP) with a hidden layer size of 100, using the Adam optimizer \citep{kingma-et-al-2015-adam} and training for 3000 steps. The number of layers and layer size was selected using validation set performance, while the number of steps was chosen based on loss convergence on the training set. We find similar patterns of performance for most combinations of predictors. However, we see substantial improvements in performance for combinations of features which include \added[id=r2]{both magnitude and variability features}; for example, $\big(\chgform,\varform\big)$ improving from $69 \pm 1\%$ to $73 \pm 1\%$. Perhaps as a result of this, we achieve a test-set accuracy of $89\pm 1\%$, when using all four predictors---representing a 6-point improvement over the best linear model, as well as a 4-point improvement over the best combination of three measures using the MLP $\big(\chgemb,\varemb,\varform\big)$. This therefore suggests that while the variability features are the most descriptive of UniMorph's categorization of inflection/derivation, all four features contain unique information relevant to recreating this distinction (Hypothesis E).

\section{Classification of Linguistic Types of Inflection}
\label{sec:canon}
Given the controversy over what should be considered inflection and derivation, a model that largely aligns with a typical operationalization of the distinction (UniMorph 4.0) may also be of interest in the ways in which it {\em differs} from that operationalization. Accordingly, in this section, we look at the trends in how our model classifies constructions which are labelled as inflection in UniMorph.
\added{We consider several distinctions which we believe to be of linguistic interest, specifically: what kind of meaning is expressed by an inflection; whether it is {\em transpositional} (changes the part of speech); and whether it is {\em contextual} or {\em inherent} (as described by \citealt{booij-1996-inherent}). We ask whether these distinctions affect how likely an inflectional construction is to be classified correctly under our best model (the MLP with all four measures). We focus only on inflectional constructions because UniMorph has cross-linguistically consistent featural annotations on inflections that we can use for the analysis; no such cross-linguistically consistent annotation exists for derivation.
}

\subsection{Categories of inflectional meaning}
We first consider several categories of inflectional meanings: features for mood (e.g. indicative, subjunctive); tense (present, past...); number (singular, dual, plural...); voice (active, passive); comparison (comparative, absolute/relative superlative, equative); gender, and case. These categories of meaning are often used to structure accounts of inflection, such as UniMorph's description of its feature set \citep{sylak-glassman-2016-composition} as well as theoretical accounts like
\citet{anderson-1985-inflectional} and even \citeauthor{haspelmath-2024-inflection}'s (\citeyear{haspelmath-2024-inflection}) retro-definition of inflection. \added{It is, however, worth noting that} not all sources agree on all of these categories \added{as being inflectional. For example,} Haspelmath rejects voice as inflectional, and comparison is \added{often omitted from discussions of} major cross-linguistic inflectional categories (as is the case in both \citealp{anderson-1985-inflectional} and even \citealp{haspelmath-2024-inflection}), and is considered {\em inherent inflection} (which is less canonical) by \citet{booij-1996-inherent}. One might reasonably expect constructions which \added{are semantically marked for} these controversial categories to be {\em more likely to be classified as derivation} by our model.

\added{Note that linguists generally agree on which categories of meaning are semantically marked across languages \citep{greenberg-1966-universals,silverstein-1986-hierarchy,croft-2002-typology,ackema-et-al-2019-default},
and semantic markedness often corresponds to morphological marking. For example, past tense is generally considered more semantically marked than present, and in many languages the past tense requires an affix while the present tense does not. However, the UniMorph annotations include both the semantically marked and unmarked inflections (e.g. V;PAST;PL and V;PST;PL for Ukrainian verbs).}
Therefore,
for the purposes of this analysis, we consider active voice, singular number, nominative case,\footnote{While some languages have been argued to mark for nominative case with accusative being unmarked \citep{konig-2006-marked} no such language is present in our study.} and present tense unmarked values, even when present in the featural description of a construction.
\added{For example, in Ukrainian verb annotations, V;PAST;PL would be considered marked for tense and number, while V;PST;SG would be considered unmarked for both; both verbs would be unmarked for voice and mood since these are not in the featural descriptions.}
For the category of gender, we simply consider nouns \added{not to be marked, as their gender is typically not a morphological process but a lexical property}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]
  {figures/infder/odds.pdf}
  \caption
  {Probability and Odds ratio with 95\% confidence intervals of being classified as derivation  for various kinds of inflectional meaning. Inflections to the right of the dotted line were disproportionately likely to be classified as derivation by our model}
  \label{fig:odds_meaning}
\end{figure}

Figure~\ref{fig:odds_meaning} displays the probability that a construction marking for one of these inflection types will be classified as derivation by our best-performing model. As can be seen in the figure, our model does not classify any of these major kinds of inflection as {\em more derivational than inflectional}; each is substantially more likely to be classified as inflection than derivation. This finding is perhaps unsurprising given our model's cross-linguistic \added[id=r2]{test set} classification accuracy of 90\%---it classifies 92\% of inflections correctly in general. Accordingly, classifying just 15-20\% of constructions belonging to a particular inflectional category as derivations has the potential to be significant.

In order to answer the question ``Are constructions which mark for this inflection type significantly more  likely to be classified as derivational than others?'', we compute the odds ratio.
We focus on the best performing MLP model (using all 4 features) in these results, which are presented in Figure~\ref{fig:odds_meaning} with 95\% confidence intervals. Constructions with an odds ratio significantly greater than 1, while not more likely to be classified as derivation than inflection, can nevertheless be thought of as particularly {\em non-canonical} types of inflection under our model, while those with odds ratios significantly below 1 are {\em canonical} with respect to our model.

We apply the Boschloo exact test \citep{boschloo-1970-raised} to the results and correct for multiple comparisons with the Bonferroni correction, which yields a significance level of $0.05/7=0.007$.
We find the odds ratios for gender $(p=1\times10^{-7})$, tense $(p=3\times10^{-7})$, and mood $(p=1\times10^{-7})$
significant. This identifies gender, mood, and tense as particularly canonical inflectional distinctions under our model---all of which are well in line with the claims of Haspelmath and others.

While we do not identify any inflectional meaning categories which are significantly more likely to be classified as derivations than the average inflections, the categories of passive voice $(p=0.03)$ and comparatives $(p=0.08)$ each have 95\% confidence intervals which are almost exclusively larger than 1. Each of these categories has been discussed as less canonical kinds of inflection, with comparatives even occasionally being listed as derivations within UniMorph.\footnote{For example, they are listed as derivations in English, but as inflections in German.} As these are the two least common categories in our sample (consisting of just 57 comparative constructions and 41 passives), it may be that these effects would be significant with a larger sample; alternatively, their relatively high likelihood of being classified as derivation could be an artefact of their rarity in our sample.
\subsection{Inherent vs. contextual inflection and transpositions}
While we do not find any categories of inflectional {\em meaning} as non-canonical under our model, we also consider two other major categories of inflection that have been discussed in the linguistic literature as potentially non-canonical: inherent inflection and transpositions, for which results are displayed in Figure~\ref{fig:odds_other}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]
  {figures/infder/odds_other.pdf}
  \caption
  {Probability and Odds ratio with 95\% confidence intervals of being classified as derivation  for inherent inflections and transpositions}
  \label{fig:odds_other}
\end{figure}

First, we consider \citeauthor{booij-1996-inherent}'s (\citeyear{booij-1996-inherent}) notion of inherent and contextual inflection.
\added{Booij describes contextual inflection as canonical: it is determined by the syntactic context in which a word appears and indicates agreement (e.g. plural marking on a verb, which is controlled by its subject). In contrast, inherent inflection is non-canonical: it contributes to the meaning of the word itself (e.g.\ the plural noun).}
To operationalize this in a simple, cross-linguistically consistent way, we associate number, gender, and case\footnote{\citet{booij-1996-inherent} makes the distinction between structural and semantic case, with the former being contextual inflection and the latter inherent. However, due to the complexity in drawing a line between these categories, we treat all case marking on nouns as inherent.} with nouns---meaning that when those features appear on other parts of speech, we consider them contextual inflections. Analogously, we associate mood, tense, and voice with verbs. We then may consider whether an inflection is {\em inherent} or not, where we define inherency as not marking {\em any} contextual features. As shown in Figure~\ref{fig:odds_other}, we find that inherent inflectional constructions are not more likely to be classified as derivation than inflection; however, they {\em are} significantly more likely to be classified as derivation compared to other types of inflections, as quantified by the odds ratio $(p=6\times10^{-9})$. Interestingly, though, we find this to be almost entirely due to nominal inherent inflection $(p=2\times10^{-8})$, rather than verbal inherent inflection $(p=0.7)$. We see this exemplified in Figure~\ref{fig:odds_inher}, which shows that inherent case is significantly associated with being classified as derivation $(p=1\times10^{-5})$, while contextual case $(p=0.003)$ and contextual number $(p=0.0008)$ are significantly associated with being classified as inflection.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]
  {figures/infder/odds_inher.pdf}
  \caption
  {Probability and Odds ratio with 95\% confidence intervals of being classified as derivation  for inherent vs. contextual noun inflections}
  \label{fig:odds_inher}
\end{figure}

Finally, we consider inflectional transpositions, denoted in UniMorph as participles (deverbal adjectives), converbs (deverbal adverbs), and masdars (deverbal nouns), shown in Figure~\ref{fig:odds_other}. Transpositions have often been argued to be non-canonical inflection or even derivation because transpositions change the part of speech \citep{spencer-2013-lexical, plank-1994-inflection, haspelmath-2024-inflection}. We here find under our model that transpositions appear neither significantly more or less likely to be classified as derivations than inflections by our model---neither particularly canonical nor non-canonical. This may be due to the non-contextual nature of our embedding model: many inflectional transpositions are syncretic with a non-transpositional form, and our model must assign these the same location in embedding space. Thus, our null result here should not be taken as strong evidence against considering transpositions as non-canonical.

\subsection{Summary}

\added{In this section, we have investigated different kinds of inflectional constructions discussed in the linguistics literature to see whether any of these are particularly {\em canonical} or {\em non-canonical} under our model. That is, we looked at whether our model is more (or less) likely to correctly classify these constructions as inflectional, relative to the average inflectional construction.}

We identify mood, tense, and gender as {\em canonical inflections} under our model, but we do not find any categories of inflectional meaning which are significantly {\em non-canonical} in our sample. We find that inherent inflections are significantly more likely to be classified as derivations, in line with \citeauthor{booij-1996-inherent}'s (\citeyear{booij-1996-inherent}) view of them as non-canonical inflection.  Interestingly, we find this is driven by inherent nominal inflections rather than inherent verbal inflections. Finally, we investigate transpositions (typically thought of as non-canonical inflection), finding no evidence that they are either canonical or non-canonical under our model.

\section{Discussion}

\subsection{The role of our individual measures}\label{sec:featureimp}
As shown in Section~\ref{sec:classify}, all four of our measures can be used to achieve better discrimination between traditional concepts of inflection and derivation; however, not every feature plays an equally large  role. In this section, we discuss the roles played by each of our features and their connection to linguistic theory.

Among our four measures, our results point to variability of the change in distributional embedding \varemb being the most relevant to traditional categorizations of inflection and derivation. This is in line with the findings of \citet{bonami-et-al-2018-inflection} and \citet{copot-et-al-2022-idiosyncratic} in French, who focus on similar measures as a proxy for semantic drift, as part of a theory where traditional concepts of inflection and derivation reflect higher or lower {\em paradigmatic predictability}. Indeed, it is possible that this measure could be (roughly) equivalent to \citeauthor{copot-et-al-2022-idiosyncratic}'s (\citeyear{copot-et-al-2022-idiosyncratic}) predictability of frequency, as it is motivated from a similar theoretical basis. On the other hand, our measure is much simpler to define and compute: attempting to produce a measure of {\em predictability} immediately raises complex issues around on {\em what basis} such predictions should be made, complicating the interpretation of results.

In addition, we find a clear and complementary influence of the variability of the change in form, \varform: adding this feature to our model produces a large increase in performance, even when \varemb is already included. This measure \added[id=r2]{(described in Section~\ref{sec:ortho})} can be thought of as \replaced[id=r2]{a weighted measure of allomorphy, capturing not just the number of distinct patterns, but also their similarity}{describing the complexity of the structural relationship between base forms and constructed forms}. Our results point to \replaced[id=r2]{a much higher degree of formal variability/allomorphy for inflections than derivations}{this relationship being much more complex for inflections than derivations} across a wide range of languages, contrary to the predictions of \citet{plank-1994-inflection} and \citet{dressler-1989-prototypical}, but in line with the argument in~\cref{sec:formal-dim}. Although work on French has suggested little difference in the {\em predictability} of form for derivational and inflectional constructions \citep{bonami-et-al-2019-paradigm}, we clearly find within our sample of languages evidence that the {\em actual degree of variation} is very different.

Superficially, this finding could appear to be caused by the fact that derivational allomorphs are sometimes not collapsed in UniMorph data (e.g. \textit{–heit} and \textit{–keit} being listed as different morphemes in German). However, when we looked into this issue, we found that most derivations had 0–1 such uncollapsed allomorphs. Combining two allomorphs in this way would add at most half the edit distance between the morphs to our measure. In most cases, the edit distance between these allomorphs is 1–2, adding just $0.5$–$1.0$ to the value of \varform. This is much less than the difference between the means of the two categories in this feature, suggesting that failure to collapse allomorphs is not the primary source of this finding. Returning to the example of {\em –heit} and {\em –keit} within German, we find {\em –heit} has \varform of 1.53 and {\em –keit} has \varform of 1.25. The two morphemes occur 27\% and 73\% of the time respectively. When combined, they have a \varform of 2.43–--still well within the derivational range.

\added{Similarly, one might object that not only such straightforwardly-conditioned allomorphs must be accounted for, but also more idiosyncratic variants that express the same meanings. For example, in French, such formally distinct forms as {\em -age}, {\em -ance}, and {\em -ure} could be argued to be allomorphs of a single action-noun forming morpheme. \citet{copot-et-al-2022-idiosyncratic} handle this by grouping morphemes with similar semantics, by computing average difference vectors in embedding space between base and constructed form for each morpheme, and agglomeratively clustering morphemes with difference vectors with cosine similarity over 0.7. We find such clustering of our data \deleted[id=r2]{is} does not sufficiently align with semantic categories of morphemes across our full range of languages to reformat our analysis around it. However, even when clustering derivations with  this threshold of similarity, we still find a much lower degree of formal variability  for derivations than inflections. On average across languages, 38\% of derivational constructions cluster with nothing else at all, without increasing variability. The average cluster contains just 1.8 morphemes, with  inflectional morphemes, which are not clustered in this way, exhibiting still 208\% more allomorphs on average than derivational clusters.}

Future studies should explore the relevance of the variability of form further, to see if it is robust to different languages, and focus directly on the validity of this measure. However, we note that our best performing model without this feature, the MLP with the features $\big(\chgform, \chgemb, \varemb \big)$ achieves a classification accuracy of $81\pm 1\%$, which is still 23 points above predicting the majority class.

Finally, our results show smaller influence of the magnitude measures \chgform and \chgemb. This finding seems to contrast with Spencer's general claim that derivations are associated with larger changes to the properties of a lexeme, but it is not entirely contradictory. In particular, \chgemb still displays a fairly strong correlation with inflection and derivation on its own, and likely does not contribute as much to our models due to its substantial correlation (Pearson's $r$: 0.86) with the more strongly predictive \varemb. In the case of \chgform, we find little evidence here that derivations have a tendency to produce larger changes to the form; however, this may be in part related to our need to remove constructions which are orthographically syncretic between the base form and constructed form (which are dominantly considered inflectional in our sample of languages). The length of the change in form does seem to play a small role as a part of a composite set of factors based on its use in our best-performing MLP model.

\added{As noted in Section~\ref{sec:embedding}, our use of FastText somewhat complicates the interpretation of the role of the distributional measures, in the sense that embeddings based on sub-words may capture some formal similarity between words as well as semantic and syntactic similarity. However, we note that if the embeddings do capture formal similarity, at least some of this information must be complementary to that captured by our form-based measures, since including both types of features yields a better classifier than either alone. We also performed some supplementary experiments with Word2Vec embeddings to check that distributional features without sub-word information are also useful.}\footnote{For more details about these experiments, see Appendix~\ref{app:word2vec}.} \added{While overall performance of the classifier was lower (likely due to overall worse quality of the embeddings, for the reasons described in Section \ref{sec:embedding}), we still found a non-trivial contribution from the distributional features.
So, while we can say that both formal and distributional properties are associated with the inflection-derivation distinction, further work is needed to clearly distinguish semantic, syntactic, and formal properties.}

\subsection{Language generality}\label{sec:langgen}
An important aspect of our model is its lan\-guage-ge\-ne\-ra\-li\-ty. A major limitation of existing computational studies of the in\-flec\-tion–derivation distinction \citep{copot-et-al-2022-idiosyncratic,rosa-et-al-2019-attempting,bonami-et-al-2018-inflection} is their focus on single European languages. In particular, \citet{haspelmath-2024-inflection} argues that many properties of inflection and derivation are not proven to apply in a consistent way across languages (especially non-European and non-Indo-European languages). Our model achieves high accuracy across languages, while using no language-specific features. As such, it suggests that across the languages in our sample, inflection and derivation show cross-linguistically similar distributional properties.

Given the large number of European languages in our sample, this result clearly suggests that, at least in the Indo-European family, inflection and derivation are associated with distinct signatures in terms of both their distribution and their form (at least, as expressed in orthography). While evidence for such claims has been provided in specific languages by \citet{copot-et-al-2022-idiosyncratic}, \citet{bonami-et-al-2018-inflection}, and \citet{rosa-et-al-2019-attempting}, many large subfamilies within the Indo-European language family had previously been untouched by this literature. Our study includes several Germanic languages with distinctive morphological traits, as well as
Armenian, Latvian, Irish, and Greek, covering many smaller European branches of the Indo-European family.
We also expand the evidence for consistency in the application of the terms ``inflection'' and ``derivation'' within the Romance and Slavic language families. This broad coverage overall provides quantitative evidence for the cross-linguistically consistent application of the inflection–derivation distinction within the languages of Europe---not only in terms of the morphosyntactic traits of these constructions, as framed by \citet{haspelmath-2024-inflection}, but also in terms of corpus-based measures which are a proxy for the linguistic intuitions and subjective tests Haspelmath argues should be abandoned.

In addition to this robust evidence that these properties can discriminate inflection and derivation within Indo-European languages, we also show evidence of a degree of applicability to a wider range of languages.
On this subset of languages, our best MLP classifier averages 82\% accuracy on the test set, lower than for the Indo-European languages (average 91\% accuracy).
While this is still well above the majority class baseline (74\% accuracy on this subset), it suggests that the application of the inflection–derivation distinction to non-Indo-European languages may indeed be less consistent, as suggested by Haspelmath. Of particular note are the \deleted{low} results for Turkish. Turkish is a highly agglutinative language with, according to traditional descriptions, an exceptionally rich inflectional system---reflected by an extremely large number of inflectional constructions and relatively small number of derivations in our dataset. Our classifier over-uses the label derivation for this language---classifying all derivations correctly, but also classifying many inflections as derivations. This suggests a misalignment between the orthographic and distributional tendencies observed in European languages, and the way linguists typically operationalize inflection and derivation in this language. On a theoretical level, then, our results are therefore compatible with either a view where we should think of some of these so-called inflections in Turkish as more derivational, or a view where these corpus-based measures are less accurate indicators of what ``should'' be considered inflection for Turkish.

Due to the relatively small number of non-Indo-European languages and constructions from these languages we are able to consider in the present work, we are unable to draw definitive general conclusions about cross-linguistic consistency in our measures with languages outside Europe. Our results here seem to point to an intermediate view where these corpus-quantifiable correlates of inflection and derivation are {\em less reliable} descriptors of the way the distinction is made outside of Indo-European languages but still explain {\em substantial amounts} of the distinction.

\subsection{The classification approach}\label{sec:whyclass}

Another key differentiating aspect of our work from previous computational studies is our focus on classification of constructions. This method allows us to quantify {\em how much} of the inflection–derivation distinction, as operationalized across a wide range of languages, can be explained by our simple set of corpus-based correlates. Our focus on a wide range of languages necessitates the use of a quantitative method such as classification, and contrasts with the single-language studies of \citet{bonami-et-al-2018-inflection} or \citet{copot-et-al-2022-idiosyncratic}, who focus more on discussing individual constructions.

Further, our goal of looking at whether {\em multiple features} produces a more clear-cut and less gradient view of inflection compared to the single correlates examined by \citet{bonami-et-al-2018-inflection} or \citet{copot-et-al-2022-idiosyncratic} prevents us from simply doing a statistical test of correlation between a feature and inflection/derivation. While we avoid this by training a classification model, \citet{rosa-et-al-2019-attempting} solve this problem by using clustering. We believe doing so conflates two questions about the measures under consideration. First is the question of how {\em consistent} linguists' categorizations are in terms of the measures. Secondly, there is the question of how {\em natural} the traditional categories of inflection and derivation appear with respect to these measures. This first question is a lower bar than the latter: it may be possible to use these measures to determine inflectional or derivational status, regardless of whether they form natural clusters in the feature space.

Nevertheless, a finding of {\em consistency} without {\em naturalness} is still interesting, given that decisions about what to consider inflection and derivation were made without access to these measures. For example, consistency with respect to these measures could make them a successful ``retro-definition'' in the terms of \citet{haspelmath-2024-inflection}. The clustering approach may also fail to identify a distinction where inflection and derivation are predominately located in only slightly overlapping regions of the feature space but do not necessarily form natural clusters.\footnote{As described in Section~\ref{sec:grad} and shown in Figure~\ref{fig:gradient}, it is this situation in which we find ourselves.} It is this question of consistency which we primarily consider in this paper, leading us to eschew the unsupervised clustering approach for supervised classification.

Another advantage of our focus on classification is that it naturally lends itself to testing the {\em generalizability} of our claims: by holding out a random subset of our constructions for testing data and computing accuracy on that set, we confirm that our results do not over-fit to the constructions in the training set.

\subsection{Inflection and derivation: gradient or categorical?}\label{sec:grad}
Whether the inflection–derivation distinction is principally a gradient or categorical phenomenon is a long-standing debate within linguistic theory with potentially wide-ranging implications about the nature of linguistic representations. Many theories of morphological grammatical organization, production, and processing implicitly or explicitly employ the ``split morphology hypothesis,'' which holds that inflection and derivation are separated in the grammar \citep{perlmutter-1988-split,anderson-1982-wheres}. Those who propose such separate structures rely on both the distinction between inflection and derivation being discrete and the specifics of that distinction---i.e., what morphological constructions in what languages are considered either inflectional or derivational.

On the other hand, a growing body of linguistic theory rejects a hard distinction \citep[e.g.][]{bybee-1985-morphology,spencer-2013-lexical,dressler-1989-prototypical,stekauer-2015-delimitation,corbett-2010-canonical,bauer-2004-function}. In its place, they often treat inflection and derivation as a gradient, perhaps emergent out of deeper phenomena. This view has been borne out in the computational work of \citet{bonami-et-al-2018-inflection} and \citet{copot-et-al-2022-idiosyncratic} who find clear continuous gradience with respect to their metrics and the categories of inflection and derivation.

While, as discussed in \ref{sec:whyclass}, we focus primarily on the {\em consistency} of traditional categories of inflection and derivation, in this section we briefly investigate whether, under our measures, the distinction between inflection and derivation appears more {\em gradient} or more {\em categorical}. If the former is the case, we expect a relatively even distribution of constructions in feature space, which (perhaps gradually) transition from being traditionally classified as inflection to being traditionally classified as derivation. In the categorical case, however, we expect {\em clusters} within feature space with relatively few constructions lying in intermediate ambiguous regions.

We focus on four measures in this study, so we are unable to directly visualize in the feature space. While we applied principal component analysis to produce a two-dimensional representation of our full feature space, the principal components did not pattern into inflectional and derivational regions. This is certainly evidence against  {\em naturalness} of the traditional distinction with respect to our measures. However, we may also look at our two most strongly predictive measures, as shown in Figure~\ref{fig:gradient}. Recall that a logistic classifier using only these features was able to correctly classify \added[id=r2]{$83\pm 1\%$} of constructions. Our results with our measures are here consistent with the existing findings of a gradient, rather than categorical, distinction between inflection and derivation with respect to traditional linguistic tests/measures which operationalize them---we observe a spread of constructions in the two-dimensional feature space with a smooth transition between regions containing almost exclusively inflections and regions containing almost exclusively derivations.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/infder/gradient.pdf}
  \caption
  {Our two most predictive measures for inflection and derivation. \added{Saturation represents overlapping constructions.} With respect to these two variables, the inflection–derivation distinction appears gradient rather than categorical}
  \label{fig:gradient}
\end{figure}

\subsection{Are inflection and derivation identifiable from the statistics of language?}
In this work, we have focused on identifying cross-linguistically applicable corpus-based measures, which have a consistent relationship with the traditional concepts of inflection and derivation. While we have primarily motivated the use of these corpus-based measures in terms of quantifying how consistently these categories are applied across languages or making concrete subjective linguistic tests, the fact that they are built purely from the statistics of natural language corpora allows us to consider another important question: is the inflection-derivation distinction something which is present in the statistics of language itself?

If the retro-definition given by \citet{haspelmath-2024-inflection} is the right one, for instance, the answer to this question would superficially appear to be {\em no}. Haspelmath casts the distinction in terms of morphosyntactic feature values, which themselves refer in many cases to the {\em meaning} expressed by a morphological exponent. If the specific meaning expressed by a morphological relation is necessary to distinguish which relations are inflectional in nature and which are derivational, then the typical inflection–derivation distinction requires {\em grounding} the meanings of sentences to solve---for example, no amount of raw \replaced{text}{language} input in a language can tell you whether the relationship between two words is ``agentive'' or ``plural.''

The answer to this question has implications within psycholinguistics as well as computational linguistics.  Psycholinguistics provides some empirical evidence that inflection and derivation are processed differently \citep{laudanna-et-al-1992-processing, kirkici-et-al-2013-inflection}, which seems to imply learners have some implicit ability to categorize constructions into inflection and derivation. How might a learner learn what processing to apply to a given morphological construction in this case?
A substantial body of literature indicates that humans can and do perform purely statistical learning within language acquisition \citep{swingley-2005-statistical, saffran-et-al-1996-statistical, thiessen-et-al-2013-extraction, thompson-et-al-2007-statistical, thiessen-et-al-2003-when}. Without using or even having access to the references of sentences in some cases, learners uncover important aspects of the structure of language. Our results therefore suggest the possibility that statistical learning may play a role in learning to process canonical inflection differently from canonical derivation.

This is also relevant for the validity of several constructs within natural language processing. For example, the paradigm clustering task from SIGMORPHON 2021 \citep{wiemerslage-etal-2021-findings}, which requires identifying inflectional paradigms from raw text, can only be solved if inflections and derivations can be distinguished from the \replaced{statistics of such a corpus}{linguistic signal itself}. Otherwise, derivational relations would be outputted by even the best possible system. Similarly, the task of unsupervised lemmatization \citep{kasthuri-et-al-2017-plis, rosa-et-al-2019-unsupervised} also relies on the distinction between inflection and derivation being evident \replaced{within a text corpus}{from the linguistic signal}. Our results point to these types of construct being largely valid for Indo-European languages given the high degree of discriminability between the categories, but our slightly lower results for non-Indo-European languages suggests the need for further investigation into the validity of such constructs for typologically-distant languages to those considered here.

\subsection{Classification and syntactic change}\label{sec:synoracle}
\textcolor{red}{To place an upper bound on how many of the model's errors can be explained by syntactic information, we consider how many errors can be explained by a syntactic change oracle variable. Using the annotations for part of speech in UniMorph, we produce a binary variable for whether a given construction changes the part of speech, using the start and end parts of speech for derivations. For inflections, we assume the part of speech does not change unless it is annotated by UniMorph as one of a participle, masdar, or converb. We add this oracle variable to the input to the classifier. We achieve a test-set accuracy of 84\% with the logistic classifier and 92\% with the MLP when combined with our four distributional measures. This represents a performance decrease of 2 points and increase of 2 points, respectively, suggesting little-to-no improvement to be found by a feature so closely aligned to linguistic notions of a change in part of speech.}

\textcolor{red}{However, this oracle measure captures only a very restricted notion of syntactic change: change in coarse-grained part of speech. For instance, while we treat inflectional transpositions, such as participles, as changing the part of speech in the creation of our oracle variable, this is a contentious point due to some syntactic similarities they share with verbs, which might be reflected in such a measure. On the other hand, some derivations which do not change part of speech may nevertheless change something about the syntactic context (e.g. verbal argument-structure alterations or passive constructions), and may thereby yield greater values in such a measure. A more fine-grained syntax measure which captures this might map more neatly onto the categories of inflection and derivation.
Finally, since UniMorph part-of-speech annotations are only at the construction-level, there is no variability in this syntactic information; a distributional account of syntactic information could represent individual pair variation within a construction (due to semantic drift, for example), which might be informative for reconstructing the distinction.}

\textcolor{red}{Despite these caveats, these results suggest that syntactic transposition has little added predictive power over and above our corpus-based measures. This is in line with a view of the inflection-derivation distinction where syntactic change is not definitionally related to the distinction, but epiphenomenally correlated with it.}

\subsection{Future work}
We believe our study presents a number of interesting avenues for expansion. One such possibility is the extension of the present work to a larger and more diverse sample of languages. In this work, we have taken advantage of the recently produced UniMorph 4.0 dataset to validate claims based on individual languages that corpus-based measures can capture traditional notions of inflection and derivation, and quantify how many intermediate constructions exist under such measures, but our results mostly bear on languages of Europe belonging to the Indo-European language family. While this still represents a substantial advancement in knowledge, and we do find some evidence that our results are applicable to non-Indo-European languages (as described in Section~\ref{sec:langgen}), the evidence presented here cannot yet fully refute \citeauthor{haspelmath-2024-inflection}'s (\citeyear{haspelmath-2024-inflection}) claim that inflection and derivation are much less applicable to languages outside Europe. Relatively few (590) of the constructions in our data belong to non-Indo-European languages, with even fewer (201) coming from languages spoken outside Europe, and no representation of languages from outside Eurasia. As argued by \citet{dryer-1989-large}, typological claims must be made not just with normalization with respect to language families or small geographical areas, but even large geographical areas---which is not possible with available data.  In order to properly understand to what degree the concepts of inflection and derivation map onto language generally, there is a critical need for the expansion of resources like UniMorph 4.0 and Universal Derivations \citep{kyjanek-et-al-2020-universal} to cover a larger and more representative set of languages. While UniMorph increasingly covers the inflectional morphology of a wide range of languages throughout the world, having added 65 languages from 9 non-European language families in the 4.0 release alone, no unified derivational resource covers a large number of non-European languages. The harmonization and integration of resources like derivational networks such as Hebrewnette \citep{laks-et-al-2022-hebrewnette} and finite-state morphological transducers which cover derivation such as \citet{arppe-et-al-2014-finitestate}, \citet{larasati-et-al-2011-indonesian}, \citet{strunk-2020-finitestate}, or \citet{calderonvilca-et-al-2012-analizador} into multilingual resources is essential to answering truly general typological questions with these resources in the future.

\added{Another limitation of this study that future work could address is indeed our use of the UniMorph 4.0 dataset. While UniMorph 4.0 provides the largest-scale multilingual dataset of inflection and derivation presently available, it is limited by factors related to its semi-automated construction, which may affect the way allomorphy is represented (as discussed in Section~\ref{sec:featureimp}), or other as-of-yet undiscovered systematic biases.}\footnote{\added[id=r2]{See \citet{malouf-et-al-2020-lexical} for a discussion of potential pitfalls of the UniMorph dataset for typological research.}
UniMorph represents not exactly a consensus of highly-trained linguists, but rather largely of the amateur lexicographers that make up the Wiktionary community. Accordingly, as more large-scale multilingual datasets are available, future work should investigate the degree to which these findings are robust to the method of data collection as well as the source of the data.}

Additionally, we have limited ourselves to a small set of measures here. Future work could seek to improve these measures, or look at other or additional measures. \replaced{Many previously suggested properties of these categories, such as affix ordering, have directly observable effects on the statistics of text.}{As shown in Table~2 we believe as many as 20 of Plank's subjective tests should have directly observable effects on the statistics of raw text.}
Future works could test corpus-based measures of distance from the stem or limitedness of applicability, for example. Particularly interesting, we believe, would be the investigation of a syntactic distance and variability component, drawing on works such as \citet{he-et-al-2018-unsupervised} and \citet{ravfogel-etal-2020-unsupervised}---though there are significant challenges to operationalizing these embeddings in a multilingual, low-resource domain.

There is also room for refinement of our measures \added{and classification techniques}. For example, extension to many other languages would likely require a re-assessment of our use of orthography as a proxy for linguistic form. The assumption that orthography is a reasonable proxy for form is not accurate in many languages---however, at present UniMorph does not include phonological transcriptions, and automated grapheme-to-phoneme conversion across a broad range of languages is the subject of very active research \citep{ashby-etal-2021-results}. These difficulties would need to be overcome in order to use phonological transcriptions. Future work should also investigate to what degree our variability of embedding measure is equivalent to or complementary to \citeauthor{copot-et-al-2022-idiosyncratic}'s (\citeyear{copot-et-al-2022-idiosyncratic}) predictability of frequency measure, as both are motivated from semantic drift due to a change in lexical index. Similarly, future work could \added{clarify the contribution of distributional semantics by using a model such as Word2Vec or GloVe}, or newer models of distributional semantics, such as XLM-R \citep{conneau-et-al-2020-unsupervised}---though in the latter case they would have to overcome the difficulties of multilingual decontextualization as described in Section~\ref{sec:embedding}. \added{Further, as we use only two simple classification techniques (logistic regression and an MLP), it is possible that further hyperparameter tuning or use of other techniques, such as random forests or gradient boosting, could improve on classification accuracy.}

\section{Conclusion}
In this work, we have presented the first multilingual computational study of the inflection–derivation distinction. In Section~\ref{sec:distributional} we define a small set of measures capturing the hypothesized tendency of derivation to produce bigger and more variable changes to the base form in terms of form, syntax, and semantics. We then systematically study the relationship between these measures and traditional categorizations of morphological constructions into inflection and derivation, which we derive from the UniMorph 4.0 dataset. In Section~\ref{sec:individual}, we show that these measures each correlate, in some cases strongly, with whether a construction is listed as inflectional or derivational in UniMorph 4.0. We show evidence that these correlations are not due to systematic differences in the frequency of inflectional and derivational constructions. In Section~\ref{sec:classify}, we show that both logistic regression and multi-layer perceptron classifiers which use these measures as inputs can be trained to reconstruct most of the UniMorph inflection–derivation distinction, with logistic classifier achieving a classification accuracy of $83\pm 1\%$ and the MLP achieving a classification accuracy of $89 \pm 1\%$, improving by 26 and 32 points over predicting the majority class, respectively. We identify the variability of the change in distributional embedding space \varemb and the variability of the change of form \varform as particularly strong correlates of the distinction, together able to classify $83\pm 1\%$ of constructions as they are classified in UniMorph.

Overall, these results show that much of the categories of inflection and derivation as used \replaced{in UniMorph}{by linguistic resources} can be accounted for by corpus-based measures which make concrete the subjective tests suggested by linguists. In so doing, we have also validated in a larger, multilingual context the core findings of \citet{bonami-et-al-2018-inflection} and \citet{rosa-et-al-2019-attempting}, finding that these properties hold across 26 languages (21 Indo-European and 5 others), with a model that uses no language-specific features. These well-defined, empirical measures avoid the often-discussed subjectivity and vagueness of existing criteria \citep{haspelmath-2024-inflection,plank-1994-inflection,bybee-1985-morphology}, and enable us to produce the first large-scale quantification of how consistently the categories of inflection and derivation are applied, and validate that these measures can {\em generalize} to unseen constructions.

With these measures, we are also able to identify in a quantitative way {\em how canonical} different categories of inflections are (Section~\ref{sec:canon}) in terms of properties of their form and distribution. We determine, that, as suggested by \citet{booij-1996-inherent}, inherent inflection is a {\em non-canonical inflectional category} under our model: inflectional constructions which are purely inherent are significantly more likely to be classified as derivations than other inflections under our model. We find in our sample this seems to be particularly due to {\em nominal} inherent inflections, like case and number. Furthermore, we find no traditional categories of inflectional meaning significantly non-canonical, providing some validation accounts of inflection which are structured around these categories like \citet{haspelmath-2024-inflection} or \citet{sylak-glassman-2016-composition}, though we find weak evidence that voice and comparatives could be such categories.

Finally, we note that while there is a high degree of consistency in the use of the terms inflection and derivation in terms of our measures and combining multiple measures reduces the amount of overlap between inflectional and derivational constructions, we still find many constructions near the model's decision boundary between the two categories, indicating a gradient, rather than categorical, distinction (Section~\ref{sec:grad}). This gradient region is relatively small, as suggested by our high accuracies, but does not suggest inflection and derivation as categories {\em naturally emerging} from our measures.

\subsection*{The view from lexicality}
\textcolor{red}{I now return to the broader questions and arguments in this thesis. The results in this study, finding a high degree of consistency in the application of the inflection--derivation distinction across a wide range of languages, suggest that the deployment of this distinction is perhaps somewhat less fraught than some have suggested \citep{haspelmath-2024-inflection, stekauer-2015-delimitation}, supporting cross-linguistic consistency in the application of this lexicality-related distinction. Further, the finding that a combination of corpus-based measures can reconstruct the inflection--derivation distinction with high accuracy, in addition to providing tools for analysing boundary cases, supports the argument in~\cref{ch:background} that defining a multidimensional empirical space for complex comparative concepts like inflection and derivation is a fruitful approach to understanding such concepts--similar to the development of empirical spaces for vowel typology or colour systems.}

\textcolor{red}{Do the results here support the view of inflection and derivation as a distinction of lexicality? The picture here remains somewhat mixed. We do see a moderate correlation of our measure of distributional change \chgemb with the inflection--derivation distinction, suggesting that derivations do tend to produce larger changes in distributional behaviour than inflections, as would be expected if derivations are more semantically contentful than inflections. However, this measure is highly correlated with and slightly less predictive than our measure of the variability of the change in distribution \varemb. This measure, inspired by ideas from the morphological literature about semantic drift and changes in lexical index, raises interesting questions about other levels on the lexicality continuum. If we think of inflectional and derivational constructions as two-item {\em compounds} between a lexical root and the morphological material, then the importance of \varemb could suggest that the lexicality of units at higher levels of formal structure (such as roots and words) could be reflected in the variability of distributional behaviour of these compounds. For example, the prediction is that meanings/distributions of noun--noun or adjective--noun compounds vary more than determiner--noun ``compounds''. (e.g. {\em red line} vs. {\em the line}). This would be an interesting avenue for future work.
}

\textcolor{red}{
  The contribution of the formal measures is also interesting from the perspective of lexicality. \chgform contributes very little to our best models, suggesting that the size of the change in form is not strongly related to the inflection--derivation distinction, and against the notion of lexicality as a correlation between formal size/length and semantic content. However, \varform is a useful predictor in our models, suggesting that inflections are more formally variable than derivations. Under the view I sketched in~\cref{sec:formal-dim}, this could be interpreted as inflections having less of a shared formal core than derivations, and being ``smaller'' in that sense. Overall, the results support a view of inflection and derivation as a complex combination of form and distribution, with some connections to semantic content.
}

% \section*{Acknowledgements}
% The authors would like to thank Paul J.W.\ Schauenburg, Albert Haley, Itamar Kastner, Kate McCurdy, and Francis Mollica for their comments on this work. This work was performed using resources provided by the Cambridge Service for Data Driven Discovery (CSD3) operated by the University of Cambridge Research Computing Service (\url{www.csd3.cam.ac.uk}), provided by Dell EMC and Intel using Tier-2 funding from the Engineering and Physical Sciences Research Council (capital grant EP/T022159/1), and DiRAC funding from the Science and Technology Facilities Council (\url{www.dirac.ac.uk}). This work was in part supported by the UKRI Centre for Doctoral Training in Natural Language Processing, funded by the UKRI (grant EP/S022481/1) and the University of Edinburgh, School of Informatics and School of Philosophy, Psychology \& Language Sciences.
